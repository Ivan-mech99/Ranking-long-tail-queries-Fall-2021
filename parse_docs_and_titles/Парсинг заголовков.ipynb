{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bb6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "from time import sleep\n",
    "import pymorphy2\n",
    "from pyaspeller import YandexSpeller\n",
    "from lru import LRU\n",
    "import pickle\n",
    "from time import sleep\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tarfile\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fe3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marks = pd.read_csv('train.marks.tsv', delimiter='\\t')\n",
    "df_marks = df_marks.rename(columns={\"2\": \"QueryId\", \"135041\": \"DocumentId\"})\n",
    "df_marks = df_marks.drop(columns=['1'])\n",
    "df_example = pd.read_csv('sample.csv')\n",
    "all_groups = df_marks.append(df_example)\n",
    "all_groups = all_groups.reset_index()\n",
    "all_groups = all_groups.drop(columns=['index'])\n",
    "all_groups = all_groups.sort_values(by=['QueryId', 'DocumentId']).reset_index()\n",
    "all_groups = all_groups.drop(columns=['index'])\n",
    "rev_frame = all_groups.sort_values(by=['DocumentId', 'QueryId']).reset_index()\n",
    "rev_frame = rev_frame.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d510ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606049/606049 [00:00<00:00, 1258008.69it/s]\n"
     ]
    }
   ],
   "source": [
    "query = all_groups['QueryId'].values\n",
    "doc = all_groups['DocumentId'].values\n",
    "q_to_doc = dict()\n",
    "for i in tqdm(range(query.shape[0])):\n",
    "    if query[i] not in q_to_doc:\n",
    "        q_to_doc[query[i]] = []\n",
    "    q_to_doc[query[i]].append(doc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49bd5e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606049/606049 [00:00<00:00, 688981.47it/s]\n"
     ]
    }
   ],
   "source": [
    "query_r = rev_frame['QueryId'].values\n",
    "doc_r = rev_frame['DocumentId'].values\n",
    "doc_to_q = dict()\n",
    "for i in tqdm(range(query_r.shape[0])):\n",
    "    if doc_r[i] not in doc_to_q:\n",
    "        doc_to_q[doc_r[i]] = []\n",
    "    doc_to_q[doc_r[i]].append(query_r[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381b4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('clean_title_collection')\n",
    "os.makedirs('norm_title_collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058bfd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6311/6311 [00:02<00:00, 2928.05it/s]\n"
     ]
    }
   ],
   "source": [
    "q_ind = all_groups['QueryId'].unique()\n",
    "for i in tqdm(q_ind):\n",
    "    os.makedirs('norm_title_collection/'+str(i))\n",
    "    os.makedirs('clean_title_collection/'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc476736",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e946b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "582167it [15:15, 636.06it/s]  \n"
     ]
    }
   ],
   "source": [
    "with gzip.open(\"docs.tsv.gz\") as file:\n",
    "    for line in tqdm(file):\n",
    "        a,b,c = line.decode('utf-8', errors = 'ignore').lower().strip('\\n').split('\\t')\n",
    "        title = b\n",
    "        title_data[int(a)] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee1f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_data.pickle', 'wb') as file:\n",
    "    pickle.dump(title_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76908583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'наша деятельность'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_data[135041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b908a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582167/582167 [00:00<00:00, 1916356.76it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_data = []\n",
    "for key in tqdm(title_data):\n",
    "    raw_data.append((key, title_data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c885fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x):\n",
    "    try:\n",
    "        spellchecker2 = YandexSpeller()\n",
    "        a = spellchecker2.spelled(x[1])\n",
    "    except:\n",
    "        sleep(1)\n",
    "        spellchecker2 = YandexSpeller()\n",
    "        a = spellchecker2.spelled(x[1])\n",
    "    return (x[0], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b5b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582167/582167 [10:13:45<00:00, 15.81it/s]   \n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(7) as executor:\n",
    "    results = list(tqdm(executor.map(check, raw_data), total=582167))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c7c8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spelled_title_data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a093909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582167/582167 [00:00<00:00, 1672266.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for elem in tqdm(results):\n",
    "    spelled_title_data[elem[0]] = elem[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "facf157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spelled_title_data.pickle', 'wb') as file:\n",
    "    pickle.dump(spelled_title_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ebc816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'наша деятельность'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spelled_title_data[135041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a4db9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582167/582167 [00:00<00:00, 1748581.30it/s]\n"
     ]
    }
   ],
   "source": [
    "spell_morph_title = dict()\n",
    "raw_data = []\n",
    "for key in tqdm(tmp):\n",
    "    raw_data.append((key, tmp[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c68d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def pymorphy_tokenizer(text):\n",
    "    res = []\n",
    "    for word in text.split():\n",
    "        res.append(morph.parse(word)[0].normal_form)\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7652aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582167/582167 [18:11<00:00, 533.45it/s] \n"
     ]
    }
   ],
   "source": [
    "for elem in tqdm(raw_data):\n",
    "    spell_morph_title[elem[0]] = pymorphy_tokenizer(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e39e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_title_data.pickle', 'wb') as file:\n",
    "    pickle.dump(spell_morph_title, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38fa2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'наш деятельность'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[135041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6de54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582167/582167 [00:00<00:00, 1398716.40it/s]\n"
     ]
    }
   ],
   "source": [
    "norm_title = dict()\n",
    "raw_data = []\n",
    "for key in tqdm(title_data):\n",
    "    raw_data.append((key, title_data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce5a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582167/582167 [18:19<00:00, 529.48it/s] \n"
     ]
    }
   ],
   "source": [
    "for elem in tqdm(raw_data):\n",
    "    norm_title[elem[0]] = pymorphy_tokenizer(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c716a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('norm_title_data.pickle', 'wb') as file:\n",
    "    pickle.dump(norm_title, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "939d7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_dict/norm_title_data.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a37e129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'наш деятельность'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[135041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#с заголовками все в порядке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2da447ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "582167it [00:00, 607553.63it/s]\n"
     ]
    }
   ],
   "source": [
    "#читаем урлы и id сайтов\n",
    "id_url = dict()\n",
    "url_id = dict()\n",
    "with open(\"url.data\", \"r\") as file:\n",
    "    for line in tqdm(file):\n",
    "        a,b = line.strip('\\n').split('\\t')\n",
    "        id_url[int(a)] = b\n",
    "        url_id[b] = int(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f2d0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id_url.pickle', 'wb') as file:\n",
    "    pickle.dump(id_url, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15cfdab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('url_id.pickle', 'wb') as file:\n",
    "    pickle.dump(url_id, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d562a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = pd.read_csv('queries.tsv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "005016a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = pd.read_csv('queries.tsv', delimiter='\\t', header=None)\n",
    "id_querry = dict()\n",
    "querry_id = dict()\n",
    "ids = df_q[0].values\n",
    "querrys = df_q[1].values\n",
    "for i in range(ids.shape[0]):\n",
    "    id_querry[ids[i]] = querrys[i]\n",
    "    querry_id[querrys[i]] = ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "718463bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id_querry.pickle', 'wb') as file:\n",
    "    pickle.dump(id_querry, file)\n",
    "with open('querry_id.pickle', 'wb') as file:\n",
    "    pickle.dump(querry_id, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4dbcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellchecker2 = YandexSpeller()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def pymorphy_tokenizer(text):\n",
    "    res = []\n",
    "    for word in text.split():\n",
    "        res.append(morph.parse(word)[0].normal_form)\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77b1dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6311/6311 [40:15<00:00,  2.61it/s] \n"
     ]
    }
   ],
   "source": [
    "id_querry_spelled = dict()\n",
    "id_querry_clean = dict()\n",
    "id_querry_norm = dict()\n",
    "querry_id_spelled = dict()\n",
    "for key in tqdm(id_querry):\n",
    "    id_querry_spelled[key] = spellchecker2.spelled(id_querry[key])\n",
    "    querry_id_spelled[id_querry_spelled[key]] = key\n",
    "    id_querry_clean[key] = pymorphy_tokenizer(id_querry_spelled[key])\n",
    "    id_querry_norm[key] = pymorphy_tokenizer(id_querry[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f30e3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id_querry_spelled.pickle', 'wb') as file:\n",
    "    pickle.dump(id_querry_spelled, file)\n",
    "with open('id_querry_clean.pickle', 'wb') as file:\n",
    "    pickle.dump(id_querry_clean, file)\n",
    "with open('id_querry_norm.pickle', 'wb') as file:\n",
    "    pickle.dump(id_querry_norm, file)\n",
    "with open('querry_id_spelled.pickle', 'wb') as file:\n",
    "    pickle.dump(querry_id_spelled, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4c38bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id_querry.pickle', 'rb') as file:\n",
    "    id_querry = pickle.load(file)\n",
    "with open('id_querry_spelled.pickle', 'rb') as file:\n",
    "    id_querry_spelled = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fc88374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6311/6311 [00:00<00:00, 839312.97it/s]\n"
     ]
    }
   ],
   "source": [
    "enlarged_querrys = dict()\n",
    "for key in tqdm(id_querry):\n",
    "    if id_querry[key] != id_querry_spelled[key]:\n",
    "        enlarged_querrys[id_querry[key]] = key\n",
    "        enlarged_querrys[id_querry_spelled[key]] = key\n",
    "    else:\n",
    "        enlarged_querrys[id_querry[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9037b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('enlarged_querrys.pickle', 'wb') as file:\n",
    "    pickle.dump(enlarged_querrys, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69264d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1442it [09:35,  2.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-368858f10a0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mq_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc_to_q\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mq_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'norm_title_collection/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;31m# macOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#читаем данные из gzip файла\n",
    "with gzip.open(\"docs.tsv.gz\") as file:\n",
    "    for line in tqdm(file):\n",
    "        a,b,c = line.decode('utf-8', errors = 'ignore').lower().strip('\\n').split('\\t')\n",
    "        title = b\n",
    "        title_data[int(a)] = title\n",
    "        \n",
    "        norm_title = b.split()\n",
    "        norm_title = [word for word in pymorphy_tokenizer(norm_title)]\n",
    "        norm_title = ' '.join(norm_title)\n",
    "        norm_title_data[int(a)] = norm_title\n",
    "        \n",
    "        clean_title = spellchecker.spelled(b)\n",
    "        clean_title = clean_title.split()\n",
    "        clean_title = [word for word in pymorphy_tokenizer(clean_title)]\n",
    "        clean_title = ' '.join(clean_title)\n",
    "        clean_title_data[int(a)] = clean_title\n",
    "        \n",
    "        title = title.encode('utf-8')\n",
    "        norm_title = norm_title.encode('utf-8')\n",
    "        clean_title = clean_title.encode('utf-8')\n",
    "        if int(a) in doc_to_q:\n",
    "            #norm title\n",
    "            try:\n",
    "                with gzip.open(a+'.gz', 'wb') as f:\n",
    "                    f.write(norm_title)\n",
    "            except OSError:\n",
    "                sleep(3)\n",
    "                with gzip.open(a+'.gz', 'wb') as f:\n",
    "                    f.write(norm_title)\n",
    "            q_list = doc_to_q[int(a)]\n",
    "            for elem in q_list:\n",
    "                shutil.copy2(a+'.gz', 'norm_title_collection/'+str(elem)+'/'+a+'.gz')\n",
    "            try:\n",
    "                os.remove(a+'.gz')\n",
    "            except PermissionError:\n",
    "                sleep(3)\n",
    "                os.remove(a+'.gz')\n",
    "            \n",
    "            #clean title\n",
    "            try:\n",
    "                with gzip.open(a+'.gz', 'wb') as f:\n",
    "                    f.write(clean_title)\n",
    "            except OSError:\n",
    "                sleep(3)\n",
    "                with gzip.open(a+'.gz', 'wb') as f:\n",
    "                    f.write(clean_title)\n",
    "            q_list = doc_to_q[int(a)]\n",
    "            for elem in q_list:\n",
    "                shutil.copy2(a+'.gz', 'clean_title_collection/'+str(elem)+'/'+a+'.gz')\n",
    "            try:\n",
    "                os.remove(a+'.gz')\n",
    "            except PermissionError:\n",
    "                sleep(3)\n",
    "                os.remove(a+'.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_data.pickle', 'wb') as file:\n",
    "    pickle.dump(title_data, file)\n",
    "with open('clean_title_data.pickle', 'wb') as file:\n",
    "    pickle.dump(clean_title_data, file)\n",
    "with open('norm_title_data.pickle', 'wb') as file:\n",
    "    pickle.dump(norm_title_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73443ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
