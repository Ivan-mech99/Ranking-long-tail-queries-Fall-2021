{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7b4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import zipfile\n",
    "import shutil\n",
    "from time import sleep\n",
    "import pickle\n",
    "from time import sleep\n",
    "import sys\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dba76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('query_dict/id_querry_spelled.pickle', 'rb') as file:\n",
    "    id_querry_clean = pickle.load(file)\n",
    "with open('title_dict/title_data.pickle', 'rb') as file:\n",
    "    title_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a54391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marks = pd.read_csv('train.marks.tsv', delimiter='\\t', header=None)\n",
    "df_marks = df_marks.rename(columns={0: \"QueryId\", 1: \"DocumentId\"})\n",
    "df_marks = df_marks.drop(columns=[2])\n",
    "df_example = pd.read_csv('sample.csv')\n",
    "all_groups = df_marks.append(df_example)\n",
    "all_groups = all_groups.reset_index()\n",
    "all_groups = all_groups.drop(columns=['index'])\n",
    "all_groups = all_groups.sort_values(by=['QueryId', 'DocumentId']).reset_index()\n",
    "all_groups = all_groups.drop(columns=['index'])\n",
    "rev_frame = all_groups.sort_values(by=['DocumentId', 'QueryId']).reset_index()\n",
    "rev_frame = rev_frame.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39232d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e16ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro_feats = dict()\n",
    "neuro_feats['use-multilingual/3_unnormed_512_texts'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a305562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6311/6311 [11:35:24<00:00,  6.61s/it]  \n"
     ]
    }
   ],
   "source": [
    "q_ids = all_groups['QueryId'].unique()\n",
    "for q1 in tqdm(q_ids):\n",
    "    corpus = []\n",
    "    tmp = all_groups[all_groups.QueryId==q1]\n",
    "    docs = tmp['DocumentId'].values\n",
    "    for doc1 in docs:\n",
    "        with gzip.open(\"doc_collection/{}/{}.gz\".format(q1, doc1)) as file:\n",
    "            for line in file:\n",
    "                a = line.decode('utf-8', errors = 'ignore').lower().strip('\\n').split('\\t')\n",
    "                a = ' '.join(a[0].split()[:512])\n",
    "        corpus.append((a, doc1))\n",
    "    cur_q = id_querry_clean[q1]\n",
    "    one_tok_txt = cur_q.split()\n",
    "    Q_emb = model1(cur_q)\n",
    "    for doc1 in corpus:\n",
    "        D_emb = model1(doc1[0])\n",
    "        neuro_feats['use-multilingual/3_unnormed_512_texts'].append(cosine_similarity(Q_emb.numpy(), D_emb.numpy()).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0462b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('use-multilingual_3_unnormed_512_texts.pickle', 'wb') as file:\n",
    "    pickle.dump(neuro_feats, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6d290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
